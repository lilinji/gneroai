---
title: ParallelFold 高性能并行结构预测指南
sidebar_position: 15
description: 详细介绍ParallelFold在HPC集群上进行高性能并行蛋白质结构预测的企业级完整指南
keywords: [ParallelFold, AlphaFold, 并行计算, 蛋白质结构预测, 高性能计算, GPU加速]
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

# ParallelFold 高性能并行结构预测指南

本指南详细介绍如何在HPC集群上使用ParallelFold进行高性能并行蛋白质结构预测，包括单体蛋白和复合物的快速预测方法。

## 概述

### 什么是ParallelFold

ParallelFold是由上海交通大学开发的高性能并行蛋白质结构预测平台，基于AlphaFold架构进行了重要的性能优化：

**核心优势：**
- **极速预测** - 将原本数小时至数天的AlphaFold计算压缩至分钟级
- **并行流水线** - 支持大规模并行计算，显著提升吞吐量
- **智能调度** - 自动评估序列复杂度并动态分配最优GPU/CPU资源
- **显存优化** - 采用先进的显存管理策略，降低硬件要求

**技术创新：**
- 后端集成AlphaFold单体与多体模型
- 并行流水线设计，支持多序列同时处理
- 智能资源调度系统
- 显存优化策略，提高GPU利用效率

### 性能对比

ParallelFold相比传统AlphaFold的性能提升：

| 预测类型 | AlphaFold 2 | ParallelFold | 加速比 |
|----------|-------------|--------------|--------|
| **单体蛋白(300aa)** | 2-4小时 | 10-30分钟 | 5-10倍 |
| **单体蛋白(800aa)** | 4-8小时 | 30-60分钟 | 6-12倍 |
| **复合物(500aa)** | 8-24小时 | 1-2小时 | 8-15倍 |
| **批量处理** | 串行处理 | 并行处理 | 10-50倍 |

### 应用场景

ParallelFold在以下领域具有重要价值：

| 应用领域 | 具体场景 | 技术优势 |
|----------|----------|----------|
| **结构基因组学** | 大规模蛋白质结构预测 | 高吞吐量并行处理 |
| **药物设计** | 靶点蛋白结构快速获取 | 分钟级预测速度 |
| **蛋白工程** | 突变体结构快速评估 | 批量处理能力 |
| **系统生物学** | 蛋白质复合物网络分析 | 复合物预测支持 |

## 环境与部署

### 容器化架构

我们采用Singularity容器化部署ParallelFold，确保计算环境的一致性：

**系统配置：**
```bash
容器路径: /hpcfs/fpublic/container/singularity/app/parallelfold/parallelfold.sif
数据库路径: /hpcfs/fpublic/database/alphafold/data/
支持GPU: RTX 3090/4090/A40/A800
CUDA版本: 11.8+
```

**技术架构特点：**
- ✅ 预配置完整的AlphaFold环境
- ✅ 内置优化的并行计算框架
- ✅ 支持多GPU并行加速
- ✅ 智能资源调度系统
- ✅ 一站式部署解决方案

### 环境验证

使用前建议验证计算环境：

```bash
# 检查容器可用性
singularity exec /hpcfs/fpublic/container/singularity/app/parallelfold/parallelfold.sif \
  python3 -c "import tensorflow as tf; print(f'TensorFlow: {tf.__version__}, GPU可用: {tf.config.list_physical_devices(\"GPU\")}')"

# 验证GPU支持
nvidia-smi --query-gpu=name,memory.total,compute_cap --format=csv

# 检查数据库完整性
ls -la /hpcfs/fpublic/database/alphafold/data/
```

## 预测模式详解

### 1. Monomer模式（单体预测）

适用于单个蛋白质序列的高速结构预测：

<Tabs>
<TabItem value="features" label="模式特点">

**工作原理：**
- 自动拆分FASTA文件中的每条序列
- 每个序列独立进行并行预测
- 支持批量单体蛋白处理
- 生成独立的预测结果

**适用场景：**
- 大规模蛋白质结构基因组学项目
- 单个蛋白质的快速结构获取
- 蛋白质变体的批量分析
- 结构注释和功能预测

**输出特点：**
- 每条序列生成独立的PDB文件
- 详细的置信度评估数据
- 完整的ID映射关系
- 并行处理时间统计

</TabItem>
<TabItem value="process" label="处理流程">

![ParallelFold单体预测流程](/static/guides/hpc/parallelfold/images/monomer_mode_config.png)

**自动化处理步骤：**

1. **序列解析** - 读取并验证FASTA格式
2. **序列拆分** - 将多序列FASTA拆分为单独文件
3. **并行调度** - 智能分配GPU资源
4. **结构预测** - 并行执行AlphaFold预测
5. **结果整合** - 收集和组织预测结果

**文件组织：**
```bash
output/
├── fasta_id_map.txt              # 序列ID映射表
├── individual_sequences/         # 拆分的单序列文件
│   ├── seq_0001.fasta
│   └── seq_0002.fasta
└── predictions/                  # 预测结果
    ├── seq_0001/
    │   ├── ranked_0.pdb         # 最佳预测结构
    │   ├── confidence.json      # 置信度数据
    │   └── timings.json         # 时间统计
    └── seq_0002/
```

</TabItem>
<TabItem value="optimization" label="性能优化">

**资源配置策略：**

```bash
# 小序列(<300aa) - 快速模式
export PF_NUM_WORKERS=8
export PF_BATCH_SIZE=2
#SBATCH --gres=gpu:1 --mem=32GB

# 中等序列(300-1000aa) - 标准模式  
export PF_NUM_WORKERS=16
export PF_BATCH_SIZE=1
#SBATCH --gres=gpu:1 --mem=32GB

# 大序列(>1000aa) - 高性能模式
export PF_NUM_WORKERS=32
export PF_BATCH_SIZE=1
#SBATCH --gres=gpu:2 --mem=64GB
```

**批量优化技巧：**
- 根据序列长度自动选择资源配置
- 使用GPU并行加速多序列处理
- 启用结果缓存避免重复计算
- 智能负载均衡提高集群利用率

</TabItem>
</Tabs>

### 2. Multimer模式（复合物预测）

适用于蛋白质复合物和多链结构的预测：

<Tabs>
<TabItem value="features" label="模式特点">

**工作原理：**
- 将所有序列作为整体处理
- 预测分子间相互作用
- 生成完整的复合物三维结构
- 支持多种复合物类型

**适用场景：**
- 蛋白质-蛋白质相互作用预测
- 多亚基蛋白复合物结构解析
- 抗原-抗体复合物建模
- 酶-底物复合物分析

**技术特点：**
- 基于AlphaFold2-multimer模型
- 支持2-8条链的复合物预测
- 预测分子间接触界面
- 评估复合物稳定性

</TabItem>
<TabItem value="process" label="处理流程">

![ParallelFold复合物预测配置](/static/guides/hpc/parallelfold/images/multimer_mode_config.png)

**复合物预测步骤：**

1. **复合物分析** - 评估链数量和总长度
2. **MSA搜索** - 针对每条链进行序列搜索
3. **配对MSA** - 构建跨链进化信息
4. **结构组装** - 预测复合物三维结构
5. **界面分析** - 评估分子间相互作用

**输入格式要求：**
```fasta
# 复合物格式示例
>chainA|Protein complex chain A
MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLR...

>chainB|Protein complex chain B
MKLLNVINFVFLMFVSSCMENSTFVSCVLYIACTPKVQLWVDSTPPP...

>chainC|Protein complex chain C
MGSPQRYEQRIGGLELWDNLSQQAELAKLLQQFAQERQAASLEIGRQ...
```

</TabItem>
<TabItem value="analysis" label="结果分析">

**复合物质量评估：**

```python
# 复合物置信度分析
{
  "overall_confidence": 0.82,      # 整体预测置信度
  "interface_confidence": 0.75,    # 界面置信度
  "chain_confidence": {            # 各链置信度
    "A": 0.89,
    "B": 0.84, 
    "C": 0.71
  },
  "interface_contacts": 45,        # 界面接触数量
  "clash_score": 2.1              # 结构冲突评分
}
```

**评估标准：**
- **整体置信度 > 0.7** - 高质量复合物预测
- **界面置信度 > 0.6** - 可信的分子间相互作用
- **冲突评分 < 5.0** - 结构合理性良好
- **接触数量 > 20** - 稳定的界面结构

</TabItem>
</Tabs>

## 使用方法

### 方法一：CHESS平台图形界面（推荐）

适合新手用户和快速原型验证的图形化操作界面：

<Tabs>
<TabItem value="login" label="平台登录">

![CHESS应用中心](/static/guides/hpc/parallelfold/images/chess_app_center.png)

**详细操作步骤：**

1. **访问CHESS平台**
   - 平台地址：https://chess.tbhpc.org
   - 使用HPC集群账户登录系统
   - 确保账户具有GPU队列访问权限

2. **进入应用中心**
   - 登录后点击左侧导航栏"应用中心"
   - 在应用列表中查找"ParallelFold"应用
   - 可使用搜索功能快速定位

3. **下载和部署应用**

![ParallelFold应用下载](/static/guides/hpc/parallelfold/images/chess_parallelfold_download.png)

   - 点击"下载"按钮开始安装
   - 应用将自动下载并添加到桌面
   - 下载完成后可在桌面找到ParallelFold图标

</TabItem>
<TabItem value="interface" label="应用界面">

![ParallelFold操作界面](/static/guides/hpc/parallelfold/images/parallelfold_interface.png)

**图形界面功能详解：**

1. **预测模式选择**
   - **Monomer模式**: 用于单体蛋白结构预测，自动将多序列FASTA拆分处理
   - **Multimer模式**: 用于蛋白质复合物预测，保持序列完整性进行联合建模

2. **输入文件管理**
   - 支持标准FASTA格式文件上传
   - 自动验证氨基酸序列格式和完整性
   - 实时显示文件上传进度和状态

3. **计算资源配置**
   - 系统智能评估序列复杂度并分配最优GPU资源
   - 当前主要支持qgpu_3090高性能GPU队列
   - 自动调整内存和CPU核心数配置

4. **作业执行参数**
   - 可设置最大运行时间限制（避免长时间占用资源）
   - 自定义输出目录路径和命名规则
   - 支持邮件通知和作业完成提醒

</TabItem>
<TabItem value="submission" label="作业提交">

**Monomer模式详细配置：**

![Monomer模式配置界面](/static/guides/hpc/parallelfold/images/monomer_mode_config.png)

**核心特点：**
- **智能序列拆分**: 后端自动将输入FASTA中的每条序列提取为独立文件
- **并行批处理**: 每个单体蛋白独立进行并行预测，显著提升处理效率
- **ID映射管理**: 自动生成`fasta_id_map.txt`记录序列标识符与输出文件的对应关系
- **资源优化**: 根据序列长度动态分配GPU和内存资源

**Multimer模式详细配置：**

![Multimer模式配置界面](/static/guides/hpc/parallelfold/images/multimer_mode_config.png)

**核心特点：**
- **整体建模**: 将所有序列作为一个完整复合物进行联合预测
- **分子间相互作用**: 预测复合物中各组分间的三维接触界面
- **复合物结构**: 输出包含所有链的完整三维结构文件
- **高级算法**: 基于AlphaFold2-multimer模型进行复合物特化预测

</TabItem>
<TabItem value="monitoring" label="作业监控">

![作业队列状态](/static/guides/hpc/parallelfold/images/job_queue_status.png)

**监控功能：**

1. **作业列表**
   - 实时查看作业状态
   - 支持作业筛选和排序

2. **详细信息**

![作业详情查看](/static/guides/hpc/parallelfold/images/job_details_view.png)

   - 点击作业名查看详细信息
   - 监控资源使用情况
   - 查看运行日志

3. **结果获取**

![输出结果目录](/static/guides/hpc/parallelfold/images/output_results_directory.png)

   - 预测完成后查看结果文件
   - 下载PDB结构文件
   - 获取置信度分析报告

</TabItem>
</Tabs>

### 方法二：命令行提交

适用于高级用户和自动化流程：

<Tabs>
<TabItem value="monomer" label="单体预测">

```bash title="单体蛋白预测流程"
# 1. 准备输入文件
cat > proteins.fasta << 'EOF'
>protein1
MKLLNVINFVFLMFVSSCMENSTFVSCVLYIACTPKVQLWVDSTPPPGTRVRAMAIYK...
>protein2
MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATP...
EOF

# 2. 提交单体预测
sbatch --job-name=pf_monomer \
       --partition=qgpu_3090 \
       --gres=gpu:1 \
       --mem=32GB \
       --time=04:00:00 \
       /hpcfs/fhome/demo/hpc/parallelfold/scripts/pf-monomer.slurm \
       proteins.fasta monomer_output/

# 3. 监控作业进度
bash /hpcfs/fhome/demo/hpc/parallelfold/scripts/pf-monitor.sh JOB_ID
```

**适用场景：**
- 序列长度 < 1000氨基酸
- 批量单体蛋白处理
- 结构基因组学项目

</TabItem>
<TabItem value="multimer" label="复合物预测">

```bash title="复合物预测流程"
# 1. 准备复合物输入
cat > complex.fasta << 'EOF'
>chainA
MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATP...
>chainB  
MKLLNVINFVFLMFVSSCMENSTFVSCVLYIACTPKVQLWVDSTPPPGTRVRAMAIYK...
EOF

# 2. 提交复合物预测
sbatch --job-name=pf_multimer \
       --partition=qgpu_3090 \
       --gres=gpu:2 \
       --mem=64GB \
       --time=12:00:00 \
       /hpcfs/fhome/demo/hpc/parallelfold/scripts/pf-multimer.slurm \
       complex.fasta complex_output/

# 3. 实时监控
watch -n 60 squeue -u $USER
```

**适用场景：**
- 蛋白质复合物预测
- 分子间相互作用分析
- 系统生物学研究

</TabItem>
<TabItem value="batch" label="批量处理">

```bash title="批量处理流程"
# 1. 组织输入文件
mkdir -p batch_input
cp protein*.fasta batch_input/

# 2. 计算任务数量
NUM_FASTA=$(find batch_input -name "*.fasta" | wc -l)
echo "发现 $NUM_FASTA 个输入文件"

# 3. 提交数组作业（并行度限制为3）
sbatch --array=1-$NUM_FASTA%3 \
       --job-name=pf_batch \
       --partition=qgpu_3090 \
       --gres=gpu:2 \
       --mem=64GB \
       --time=24:00:00 \
       /hpcfs/fhome/demo/hpc/parallelfold/scripts/pf-batch.slurm \
       batch_input/ batch_output/

# 4. 批量监控
watch -n 120 'squeue -u $USER | grep pf_batch'
```

**适用场景：**
- 大规模结构预测项目
- 高通量蛋白质分析
- 基因组规模的结构注释

</TabItem>
</Tabs>

### 方法三：直接Singularity命令

适用于定制化需求和高级优化：

```bash title="直接命令行调用"
# 基础命令格式
singularity run --nv \
    -B /database/path:/database \
    -B $(pwd):/workspace \
    /hpcfs/fpublic/container/singularity/app/parallelfold/parallelfold.sif \
    --input /workspace/input.fasta \
    --output /workspace/output \
    --mode [monomer|multimer] \
    --num_workers 16 \
    --batch_size 1 \
    --database_dir /database

# 高性能配置示例
export PF_NUM_WORKERS=32
export PF_BATCH_SIZE=1
export PF_USE_CACHE=true

singularity run --nv \
    -B /hpcfs/fpublic/database/alphafold/data:/database \
    -B $(pwd):/workspace \
    /hpcfs/fpublic/container/singularity/app/parallelfold/parallelfold.sif \
    --input /workspace/complex.fasta \
    --output /workspace/results \
    --mode multimer \
    --num_workers $PF_NUM_WORKERS \
    --batch_size $PF_BATCH_SIZE
```

## 输入格式与质量控制

### FASTA格式要求

ParallelFold支持标准FASTA格式，具体要求如下：

<Tabs>
<TabItem value="format" label="格式规范">

**基本格式要求：**
```fasta
# 标准FASTA格式
>sequence_id|description
SEQUENCE_DATA_LINE_1
SEQUENCE_DATA_LINE_2
...

# 单体蛋白示例
>protein1|Example single domain protein
MKLLNVINFVFLMFVSSCMENSTFVSCVLYIACTPKVQLWVDSTPPPGTRVRAMAIYK
QSQHMTEVVRRCPHHERCSDSDGLAPPQHLIRVEGNLRVEYLDDRNTFRHSVVVPYEP

# 复合物示例
>chainA|Complex chain A
MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATP
>chainB|Complex chain B  
MKLLNVINFVFLMFVSSCMENSTFVSCVLYIACTPKVQLWVDSTPPPGTRVRAMAIYK
```

**格式要求详细说明：**
- 描述行以`>`开头，包含唯一标识符
- 序列数据行只包含标准氨基酸字母
- 支持的氨基酸：ACDEFGHIKLMNPQRSTVWY
- 每行建议不超过80个字符（非强制）

</TabItem>
<TabItem value="validation" label="格式验证">

```bash title="FASTA文件验证脚本"
#!/bin/bash
# validate_fasta.sh - FASTA文件格式验证

FASTA_FILE="$1"

if [[ ! -f "$FASTA_FILE" ]]; then
    echo "错误: 文件不存在: $FASTA_FILE"
    exit 1
fi

echo "=== FASTA文件验证 ==="
echo "文件: $FASTA_FILE"

# 统计序列数量
seq_count=$(grep -c "^>" "$FASTA_FILE")
echo "序列数量: $seq_count"

# 检查序列长度和质量
python3 << EOF
with open('$FASTA_FILE') as f:
    lines = f.readlines()

sequences = []
current_seq = ''
current_id = ''

for line in lines:
    line = line.strip()
    if line.startswith('>'):
        if current_seq:
            sequences.append((current_id, current_seq))
        current_id = line[1:].split('|')[0]
        current_seq = ''
    else:
        current_seq += line.upper()

if current_seq:
    sequences.append((current_id, current_seq))

# 验证每个序列
valid_chars = set('ACDEFGHIKLMNPQRSTVWY')
for seq_id, seq in sequences:
    length = len(seq)
    invalid_chars = set(seq) - valid_chars
    
    print(f"序列 {seq_id}:")
    print(f"  长度: {length} aa")
    
    if invalid_chars:
        print(f"  警告: 包含非标准氨基酸: {invalid_chars}")
    
    if length < 20:
        print(f"  警告: 序列过短（< 20 aa）")
    elif length > 3000:
        print(f"  警告: 序列过长（> 3000 aa）")
    else:
        print(f"  ✓ 长度合适")

print(f"\n总体统计:")
total_length = sum(len(seq) for _, seq in sequences)
print(f"  总长度: {total_length} aa")
print(f"  平均长度: {total_length/len(sequences):.0f} aa")
EOF

echo "格式验证完成"
```

</TabItem>
<TabItem value="cleaning" label="序列清理">

```python title="序列清理工具"
#!/usr/bin/env python3
"""ParallelFold FASTA序列清理工具"""

import re
import sys
from pathlib import Path

def clean_fasta_sequence(input_file, output_file=None):
    """清理FASTA序列，移除非标准字符"""
    
    if output_file is None:
        output_file = Path(input_file).stem + "_cleaned.fasta"
    
    # 标准氨基酸字母
    valid_chars = set('ACDEFGHIKLMNPQRSTVWY')
    
    cleaned_sequences = []
    
    with open(input_file, 'r') as f:
        lines = f.readlines()
    
    current_seq = ''
    current_header = ''
    
    for line in lines:
        line = line.strip()
        if line.startswith('>'):
            # 处理前一个序列
            if current_seq:
                cleaned_seq = ''.join(c for c in current_seq.upper() if c in valid_chars)
                if len(cleaned_seq) >= 20:  # 最小长度过滤
                    cleaned_sequences.append((current_header, cleaned_seq))
                else:
                    print(f"警告: 序列过短，已跳过: {current_header}")
            
            current_header = line
            current_seq = ''
        else:
            current_seq += line
    
    # 处理最后一个序列
    if current_seq:
        cleaned_seq = ''.join(c for c in current_seq.upper() if c in valid_chars)
        if len(cleaned_seq) >= 20:
            cleaned_sequences.append((current_header, cleaned_seq))
    
    # 写入清理后的序列
    with open(output_file, 'w') as f:
        for header, sequence in cleaned_sequences:
            f.write(f"{header}\n")
            # 每80个字符换行
            for i in range(0, len(sequence), 80):
                f.write(f"{sequence[i:i+80]}\n")
    
    print(f"清理完成:")
    print(f"  输入序列: {len(lines)//2 if lines else 0}")
    print(f"  输出序列: {len(cleaned_sequences)}")
    print(f"  输出文件: {output_file}")
    
    return output_file

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("用法: python3 clean_fasta.py input.fasta [output.fasta]")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    clean_fasta_sequence(input_file, output_file)
```

</TabItem>
</Tabs>

## 输出结果分析

### 文件结构与解读

ParallelFold的输出采用标准化的目录结构：

<Tabs>
<TabItem value="structure" label="目录结构">

```bash title="典型输出目录结构"
output/
├── fasta_id_map.txt               # 序列ID映射表
├── individual_sequences/          # 拆分的单序列文件（monomer模式）
│   ├── seq_0001.fasta
│   ├── seq_0002.fasta
│   └── multimer_input.fasta       # 复合物输入（multimer模式）
├── predictions/                   # 预测结果目录
│   ├── seq_0001/
│   │   ├── ranked_0.pdb          # 最佳预测结构
│   │   ├── ranked_1.pdb          # 次优结构
│   │   ├── confidence.json       # 详细置信度数据
│   │   ├── timings.json          # 计算时间统计
│   │   └── features.pkl          # 特征数据（可选）
│   └── seq_0002/
│       ├── ranked_0.pdb
│       ├── confidence.json
│       └── timings.json
└── logs/                         # 运行日志
    ├── prediction.log
    └── error.log
```

**重要文件说明：**
- **ranked_0.pdb** - 最高置信度的推荐结构
- **confidence.json** - 完整的置信度评估数据
- **fasta_id_map.txt** - 原始序列与输出文件的映射关系
- **timings.json** - 各阶段计算时间详细统计

</TabItem>
<TabItem value="confidence" label="置信度数据">

**confidence.json文件结构：**

```json title="置信度数据示例"
{
  "plddt": [                    // 每残基置信度分数
    85.2, 89.1, 82.7, 91.3, ...
  ],
  "max_pae": 4.2,              // 最大预测对齐误差
  "ptm": 0.847,                // 整体模板建模置信度
  "predicted_aligned_error": [  // PAE矩阵
    [0, 2.1, 3.8, ...],
    [2.1, 0, 2.5, ...],
    ...
  ],
  "contact_probs": [           // 接触概率（如有）
    [0.98, 0.12, 0.05, ...],
    ...
  ]
}
```

**置信度评估标准：**
- **pLDDT > 90** - 非常高置信度（深蓝色区域）
- **pLDDT 70-90** - 高置信度（蓝色区域）
- **pLDDT 50-70** - 中等置信度（黄色区域）
- **pLDDT < 50** - 低置信度（红色区域）

**PTM分数解读：**
- **PTM > 0.8** - 优秀预测，可直接用于研究
- **PTM > 0.5** - 良好预测，建议验证关键区域
- **PTM < 0.5** - 低质量预测，需要谨慎解读

</TabItem>
<TabItem value="timing" label="性能统计">

**timings.json文件内容：**

```json title="计算时间统计"
{
  "total_time": 1782.5,        // 总计算时间（秒）
  "stages": {
    "msa_generation": 456.2,   // MSA生成时间
    "feature_processing": 123.8, // 特征处理时间
    "model_inference": 892.1,  // 模型推理时间
    "structure_relaxation": 310.4 // 结构优化时间
  },
  "gpu_utilization": {
    "average": 0.87,           // 平均GPU利用率
    "peak": 0.95,             // 峰值GPU利用率
    "memory_used": "18.2GB"   // GPU内存使用
  },
  "throughput": {
    "sequences_per_hour": 24,  // 每小时处理序列数
    "residues_per_second": 128 // 每秒处理残基数
  }
}
```

**性能分析要点：**
- MSA生成通常占总时间的20-30%
- 模型推理是最耗时的阶段（50-60%）
- GPU利用率应保持在80%以上
- 内存使用与序列长度呈指数关系

</TabItem>
</Tabs>

### 结果质量评估

<Tabs>
<TabItem value="metrics" label="质量指标">

**自动质量评估脚本：**

```python title="结果质量分析工具"
#!/usr/bin/env python3
"""ParallelFold结果质量评估工具"""

import json
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt

class ParallelFoldAnalyzer:
    def __init__(self, output_dir):
        self.output_dir = Path(output_dir)
        
    def analyze_confidence(self, confidence_file):
        """分析置信度数据"""
        with open(confidence_file) as f:
            data = json.load(f)
        
        plddt = data.get('plddt', [])
        if not plddt:
            return None
            
        analysis = {
            'mean_plddt': np.mean(plddt),
            'median_plddt': np.median(plddt),
            'high_confidence_ratio': sum(1 for x in plddt if x > 90) / len(plddt),
            'medium_confidence_ratio': sum(1 for x in plddt if 70 <= x <= 90) / len(plddt),
            'low_confidence_ratio': sum(1 for x in plddt if x < 50) / len(plddt),
            'ptm_score': data.get('ptm', 0),
            'max_pae': data.get('max_pae', float('inf'))
        }
        
        return analysis
    
    def quality_assessment(self, analysis):
        """质量等级评估"""
        if analysis is None:
            return "unknown"
            
        mean_plddt = analysis['mean_plddt']
        ptm_score = analysis['ptm_score']
        high_conf_ratio = analysis['high_confidence_ratio']
        
        if mean_plddt > 85 and ptm_score > 0.8 and high_conf_ratio > 0.6:
            return "excellent"
        elif mean_plddt > 75 and ptm_score > 0.6 and high_conf_ratio > 0.4:
            return "good"
        elif mean_plddt > 60 and ptm_score > 0.4:
            return "moderate"
        else:
            return "poor"
    
    def generate_report(self):
        """生成质量评估报告"""
        predictions_dir = self.output_dir / "predictions"
        if not predictions_dir.exists():
            print("错误: 未找到predictions目录")
            return
        
        results = []
        for pred_dir in predictions_dir.iterdir():
            if pred_dir.is_dir():
                conf_file = pred_dir / "confidence.json"
                if conf_file.exists():
                    analysis = self.analyze_confidence(conf_file)
                    quality = self.quality_assessment(analysis)
                    results.append({
                        'sequence': pred_dir.name,
                        'analysis': analysis,
                        'quality': quality
                    })
        
        # 打印报告
        print("ParallelFold结果质量评估报告")
        print("=" * 50)
        
        for result in results:
            seq_name = result['sequence']
            analysis = result['analysis']
            quality = result['quality']
            
            print(f"\n序列: {seq_name}")
            print(f"质量等级: {quality}")
            
            if analysis:
                print(f"平均pLDDT: {analysis['mean_plddt']:.1f}")
                print(f"PTM分数: {analysis['ptm_score']:.3f}")
                print(f"高置信度区域: {analysis['high_confidence_ratio']*100:.1f}%")
                print(f"低置信度区域: {analysis['low_confidence_ratio']*100:.1f}%")
        
        # 总体统计
        good_predictions = sum(1 for r in results if r['quality'] in ['excellent', 'good'])
        print(f"\n总体统计:")
        print(f"  总预测数量: {len(results)}")
        print(f"  高质量预测: {good_predictions} ({good_predictions/len(results)*100:.1f}%)")

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("用法: python3 analyze_results.py output_directory")
        sys.exit(1)
    
    analyzer = ParallelFoldAnalyzer(sys.argv[1])
    analyzer.generate_report()
```

</TabItem>
<TabItem value="visualization" label="可视化分析">

**置信度可视化脚本：**

```python title="结果可视化工具"
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import json

def plot_confidence_profile(confidence_file, output_dir):
    """绘制置信度分布图"""
    with open(confidence_file) as f:
        data = json.load(f)
    
    plddt = data.get('plddt', [])
    if not plddt:
        return
    
    residue_numbers = range(1, len(plddt) + 1)
    
    # 创建图形
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
    
    # 1. 置信度曲线图
    colors = ['red' if x < 50 else 'yellow' if x < 70 else 
              'lightblue' if x < 90 else 'blue' for x in plddt]
    
    ax1.scatter(residue_numbers, plddt, c=colors, s=2, alpha=0.7)
    ax1.set_xlabel('残基编号')
    ax1.set_ylabel('pLDDT分数')
    ax1.set_title('每残基置信度分布')
    ax1.axhline(y=90, color='blue', linestyle='--', alpha=0.5, label='高置信度阈值')
    ax1.axhline(y=70, color='orange', linestyle='--', alpha=0.5, label='中置信度阈值')
    ax1.axhline(y=50, color='red', linestyle='--', alpha=0.5, label='低置信度阈值')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. 置信度分布直方图
    bins = [0, 50, 70, 90, 100]
    counts, _ = np.histogram(plddt, bins=bins)
    colors_hist = ['red', 'yellow', 'lightblue', 'blue']
    labels = ['<50 (低)', '50-70 (中)', '70-90 (高)', '>90 (极高)']
    
    ax2.bar(range(len(counts)), counts, color=colors_hist, alpha=0.7)
    ax2.set_xlabel('置信度区间')
    ax2.set_ylabel('残基数量')
    ax2.set_title('置信度分布统计')
    ax2.set_xticks(range(len(labels)))
    ax2.set_xticklabels(labels)
    
    # 添加百分比标签
    total_residues = len(plddt)
    for i, count in enumerate(counts):
        percentage = count / total_residues * 100
        ax2.text(i, count + 0.5, f'{count}\n({percentage:.1f}%)', 
                ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig(f'{output_dir}/confidence_analysis.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"置信度分析图已保存: {output_dir}/confidence_analysis.png")

def plot_pae_heatmap(confidence_file, output_dir):
    """绘制预测对齐误差(PAE)热图"""
    with open(confidence_file) as f:
        data = json.load(f)
    
    pae_matrix = data.get('predicted_aligned_error')
    if not pae_matrix:
        return
    
    pae_array = np.array(pae_matrix)
    
    plt.figure(figsize=(10, 8))
    sns.heatmap(pae_array, cmap='viridis_r', 
                cbar_kws={'label': 'PAE (Ångström)'})
    plt.xlabel('残基编号')
    plt.ylabel('残基编号')
    plt.title('预测对齐误差(PAE)热图')
    plt.savefig(f'{output_dir}/pae_heatmap.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"PAE热图已保存: {output_dir}/pae_heatmap.png")

# 使用示例
if __name__ == "__main__":
    import sys
    if len(sys.argv) < 3:
        print("用法: python3 visualize_results.py confidence.json output_dir")
        sys.exit(1)
    
    confidence_file = sys.argv[1]
    output_dir = sys.argv[2]
    
    plot_confidence_profile(confidence_file, output_dir)
    plot_pae_heatmap(confidence_file, output_dir)
```

</TabItem>
</Tabs>

### 工作目录内容

![工作目录结构](/static/guides/hpc/parallelfold/images/working_directory_contents.png)

运行完成后，工作目录将包含：

- **输入文件** - 原始FASTA文件和预处理结果
- **预测结果** - 完整的结构文件和分析数据  
- **状态文件** - ID映射表和运行日志
- **性能数据** - 计算时间和资源使用统计

## 高级优化与故障排除

### 性能优化策略

<Tabs>
<TabItem value="resource" label="资源优化">

**智能资源配置：**

```bash title="动态资源分配脚本"
#!/bin/bash
# 根据输入复杂度自动选择计算资源

analyze_complexity() {
    local fasta_file="$1"
    python3 << EOF
import sys
with open('$fasta_file') as f:
    lines = f.readlines()

sequences = []
current_seq = ''

for line in lines:
    if line.startswith('>'):
        if current_seq:
            sequences.append(current_seq)
        current_seq = ''
    else:
        current_seq += line.strip()
        
if current_seq:
    sequences.append(current_seq)

seq_count = len(sequences)
lengths = [len(seq) for seq in sequences]
total_length = sum(lengths)
max_length = max(lengths) if lengths else 0

# 复杂度分类
if seq_count == 1 and max_length < 300:
    complexity = "simple"
elif seq_count == 1 and max_length < 1000:
    complexity = "medium"
elif seq_count <= 3 and total_length < 2000:
    complexity = "multimer_medium" 
elif seq_count <= 5 and total_length < 3000:
    complexity = "multimer_complex"
else:
    complexity = "very_complex"

print(f"{complexity}|{seq_count}|{total_length}|{max_length}")
EOF
}

# 根据复杂度选择资源配置
select_resources() {
    local complexity="$1"
    case $complexity in
        "simple")
            echo "--partition=qgpu_3090 --gres=gpu:1 --mem=32GB --time=02:00:00 --cpus-per-task=16"
            ;;
        "medium")
            echo "--partition=qgpu_3090 --gres=gpu:1 --mem=32GB --time=04:00:00 --cpus-per-task=16"
            ;;
        "multimer_medium")
            echo "--partition=qgpu_3090 --gres=gpu:2 --mem=64GB --time=08:00:00 --cpus-per-task=32"
            ;;
        "multimer_complex")
            echo "--partition=qgpu_3090 --gres=gpu:2 --mem=64GB --time=16:00:00 --cpus-per-task=32"
            ;;
        "very_complex")
            echo "--partition=qgpu_3090 --gres=gpu:2 --mem=128GB --time=24:00:00 --cpus-per-task=32"
            ;;
    esac
}
```

**批量处理优化：**

```bash title="高效批量处理策略"
# 根据序列长度自动分组
group_sequences_by_complexity() {
    local input_dir="$1"
    local output_base="$2"
    
    mkdir -p "$output_base"/{simple,medium,complex}
    
    for fasta in "$input_dir"/*.fasta; do
        complexity=$(analyze_complexity "$fasta" | cut -d'|' -f1)
        cp "$fasta" "$output_base/$complexity/"
    done
}

# 分层提交作业
submit_tiered_jobs() {
    local base_dir="$1"
    
    # 简单序列 - 高并发
    if [[ -n $(ls "$base_dir/simple"/*.fasta 2>/dev/null) ]]; then
        sbatch --array=1-$(ls "$base_dir/simple"/*.fasta | wc -l)%8 \
               --gres=gpu:1 --mem=32GB \
               pf-batch.slurm "$base_dir/simple" "$base_dir/simple_results"
    fi
    
    # 中等序列 - 中等并发
    if [[ -n $(ls "$base_dir/medium"/*.fasta 2>/dev/null) ]]; then
        sbatch --array=1-$(ls "$base_dir/medium"/*.fasta | wc -l)%4 \
               --gres=gpu:1 --mem=32GB \
               pf-batch.slurm "$base_dir/medium" "$base_dir/medium_results"
    fi
    
    # 复杂序列 - 低并发
    if [[ -n $(ls "$base_dir/complex"/*.fasta 2>/dev/null) ]]; then
        sbatch --array=1-$(ls "$base_dir/complex"/*.fasta | wc -l)%2 \
               --gres=gpu:2 --mem=64GB \
               pf-batch.slurm "$base_dir/complex" "$base_dir/complex_results"
    fi
}
```

</TabItem>
<TabItem value="memory" label="内存优化">

**GPU内存管理：**

```bash title="GPU内存优化设置"
# 内存增长策略
export TF_FORCE_GPU_ALLOW_GROWTH=true
export PF_GPU_MEMORY_LIMIT=20000  # MB

# 批次大小调整
export PF_BATCH_SIZE=1
export PF_MAX_SEQUENCES_PER_BATCH=4

# 缓存策略
export PF_ENABLE_CACHE=true
export PF_CACHE_SIZE=8GB
export PF_CLEANUP_CACHE=true

# 并行工作进程优化
calculate_workers() {
    local gpu_memory_gb="$1"
    local sequence_length="$2"
    
    # 经验公式：GPU内存(GB) / (序列长度/500 + 2)
    local workers=$(echo "scale=0; $gpu_memory_gb / ($sequence_length/500 + 2)" | bc)
    echo $((workers > 1 ? workers : 1))
}

# 动态工作进程配置
GPU_MEMORY=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
GPU_MEMORY_GB=$((GPU_MEMORY / 1024))
SEQUENCE_LENGTH=800  # 示例长度

OPTIMAL_WORKERS=$(calculate_workers $GPU_MEMORY_GB $SEQUENCE_LENGTH)
export PF_NUM_WORKERS=$OPTIMAL_WORKERS

echo "GPU内存: ${GPU_MEMORY_GB}GB"
echo "序列长度: ${SEQUENCE_LENGTH}aa"
echo "最优工作进程数: $OPTIMAL_WORKERS"
```

</TabItem>
<TabItem value="io" label="I/O优化">

**磁盘I/O优化：**

```bash title="I/O性能优化配置"
# 使用本地SSD作为临时目录
export TMPDIR="/tmp/parallelfold_${SLURM_JOB_ID}"
mkdir -p "$TMPDIR"

# 异步I/O设置
export PF_USE_ASYNC_IO=true
export PF_IO_BUFFER_SIZE=64MB

# 数据预加载
prefetch_databases() {
    echo "预加载数据库到内存..."
    
    # 将常用数据库加载到缓存
    find /hpcfs/fpublic/database/alphafold/data -name "*.h5" -exec echo 3 > /proc/sys/vm/drop_caches \;
    find /hpcfs/fpublic/database/alphafold/data -name "*.pkl" -type f -exec cat {} > /dev/null \; &
}

# 结果压缩和传输
compress_results() {
    local output_dir="$1"
    
    # 压缩大文件
    find "$output_dir" -name "*.pkl" -size +100M -exec gzip {} \;
    
    # 清理临时文件
    find "$output_dir" -name "tmp_*" -delete
    
    # 移动到长期存储
    if [[ -d "/hpcfs/farchive/users/$USER" ]]; then
        rsync -av --compress "$output_dir/" "/hpcfs/farchive/users/$USER/parallelfold_results/"
    fi
}
```

</TabItem>
</Tabs>

### 常见问题解决

<Tabs>
<TabItem value="format_errors" label="格式错误">

**FASTA格式问题：**

```bash
# 错误信息示例
Error: Invalid amino acid character 'X' found in sequence
Warning: Sequence too short (<20 aa)
```

**解决方案：**

```bash
# 1. 检查和清理非标准字符
grep -v "^>" input.fasta | grep -o "[^ACDEFGHIKLMNPQRSTVWY]" | sort -u

# 2. 自动清理序列
sed '/^>/!s/[^ACDEFGHIKLMNPQRSTVWY]//g' input.fasta > cleaned.fasta

# 3. 过滤短序列
python3 -c "
import sys
with open('input.fasta') as f:
    lines = f.readlines()

current_seq = ''
current_header = ''
for line in lines:
    if line.startswith('>'):
        if current_seq and len(current_seq) >= 20:
            print(current_header)
            for i in range(0, len(current_seq), 80):
                print(current_seq[i:i+80])
        current_header = line.strip()
        current_seq = ''
    else:
        current_seq += line.strip().upper()
        
if current_seq and len(current_seq) >= 20:
    print(current_header)
    for i in range(0, len(current_seq), 80):
        print(current_seq[i:i+80])
" > filtered.fasta

# 4. 验证清理结果
python3 /hpcfs/fhome/demo/hpc/parallelfold/scripts/validate_fasta.py cleaned.fasta
```

</TabItem>
<TabItem value="memory_issues" label="内存问题">

**GPU内存不足：**

```bash
# 错误信息
CUDA out of memory
ResourceExhaustedError: OOM when allocating tensor
```

**解决方案：**

```bash
# 1. 减少批次大小
export PF_BATCH_SIZE=1
export PF_MAX_SEQUENCES_PER_BATCH=1

# 2. 使用梯度检查点
export PF_GRADIENT_CHECKPOINTING=true

# 3. 启用内存增长
export TF_FORCE_GPU_ALLOW_GROWTH=true

# 4. 增加GPU数量
#SBATCH --gres=gpu:2

# 5. 分割长序列
split_long_sequences() {
    local input_fasta="$1"
    local max_length=1500
    
    python3 << EOF
with open('$input_fasta') as f:
    lines = f.readlines()

current_header = ''
current_seq = ''
part_num = 1

for line in lines:
    if line.startswith('>'):
        if current_seq and len(current_seq) > $max_length:
            # 分割长序列
            for i in range(0, len(current_seq), $max_length):
                print(f"{current_header}_part{i//\$max_length + 1}")
                print(current_seq[i:i+\$max_length])
        elif current_seq:
            print(current_header)
            print(current_seq)
        
        current_header = line.strip()
        current_seq = ''
    else:
        current_seq += line.strip()

# 处理最后一条序列
if current_seq and len(current_seq) > $max_length:
    for i in range(0, len(current_seq), $max_length):
        print(f"{current_header}_part{i//\$max_length + 1}")
        print(current_seq[i:i+\$max_length])
elif current_seq:
    print(current_header)
    print(current_seq)
EOF
}
```

</TabItem>
<TabItem value="performance" label="性能问题">

**预测速度过慢：**

**诊断工具：**

```bash title="性能诊断脚本"
#!/bin/bash
# performance_diagnosis.sh

JOB_ID="$1"
echo "诊断ParallelFold作业 $JOB_ID 的性能问题..."

# 1. 检查GPU利用率
echo "=== GPU使用情况 ==="
NODE=$(squeue -j $JOB_ID -h -o "%N")
if [[ -n "$NODE" ]]; then
    ssh $NODE "nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu --format=csv"
else
    echo "作业未在运行或节点信息不可用"
fi

# 2. 检查CPU和内存
echo -e "\n=== CPU和内存使用 ==="
sstat -j $JOB_ID --format=AveCPU,MaxRSS,AveRSS

# 3. 检查I/O状况
echo -e "\n=== I/O统计 ==="
sstat -j $JOB_ID --format=AveDiskRead,AveDiskWrite,MaxDiskRead,MaxDiskWrite

# 4. 检查网络和存储
echo -e "\n=== 存储性能 ==="
df -h /hpcfs/fpublic/database/

# 5. 分析日志中的性能指标
echo -e "\n=== 预测进度分析 ==="
LOG_FILE=$(find . -name "*${JOB_ID}*.out" | head -1)
if [[ -f "$LOG_FILE" ]]; then
    echo "分析日志文件: $LOG_FILE"
    
    # 提取时间信息
    if grep -q "MSA搜索" "$LOG_FILE"; then
        echo "✓ MSA搜索阶段正常"
    else
        echo "⚠ MSA搜索可能存在问题"
    fi
    
    if grep -q "结构预测" "$LOG_FILE"; then
        echo "✓ 结构预测阶段正常"  
    else
        echo "⚠ 结构预测阶段可能存在问题"
    fi
    
    # 检查错误信息
    if grep -q -i "warning\|error" "$LOG_FILE"; then
        echo "发现警告或错误信息:"
        grep -i "warning\|error" "$LOG_FILE" | tail -5
    fi
fi

# 6. 提供优化建议
echo -e "\n=== 优化建议 ==="
echo "1. 检查序列长度是否合理（建议<2000aa）"
echo "2. 验证GPU利用率是否>80%"
echo "3. 确认数据库访问是否正常"
echo "4. 考虑增加GPU数量或减少并发"
```

**性能优化配置：**

```bash
# 高性能配置
export PF_NUM_WORKERS=32        # 增加工作进程
export PF_BATCH_SIZE=1          # 优化批次大小
export PF_USE_MIXED_PRECISION=true  # 启用混合精度
export PF_OPTIMIZE_MEMORY=true  # 内存优化
export PF_PREFETCH_DATA=true    # 数据预取

# CPU优化
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK
export MKL_NUM_THREADS=$SLURM_CPUS_PER_TASK
export NUMBA_NUM_THREADS=$SLURM_CPUS_PER_TASK

# 网络优化
export PF_DOWNLOAD_TIMEOUT=300
export PF_RETRY_ATTEMPTS=3
```

</TabItem>
</Tabs>

## 完整演示流程

### CHESS平台逐步操作指南

基于实际操作录制的完整流程演示，涵盖从登录到结果获取的全过程：

![ParallelFold完整操作演示](/static/guides/hpc/parallelfold/images/parallelfold_demo.gif)

**详细操作步骤说明：**

**步骤1: 平台访问与应用获取**
1. 登录CHESS平台 (https://chess.tbhpc.org)
2. 进入应用中心，搜索并下载ParallelFold应用
3. 应用自动部署到桌面环境

**步骤2: 应用启动与配置**
1. 双击桌面ParallelFold图标启动应用
2. 进入提交任务模块进行作业配置
3. 根据预测需求选择合适的运行模式

**步骤3: 预测模式选择与设置**
- **Multimer模式**: 适用于蛋白质复合物预测，保持所有序列作为整体输入，不进行拆分，后端将整个输入写入`multimer_input.fasta`文件
- **Monomer模式**: 适用于单体蛋白批量预测，后端自动将输入FASTA中的每条序列提取为独立文件，生成ID映射关系表`fasta_id_map.txt`

**步骤4: 作业提交与资源分配**
1. 上传FASTA格式的蛋白质序列文件
2. 系统自动评估并分配到qgpu_3090队列运行
3. 提交作业并获取作业ID进行后续跟踪

**步骤5: 监控与状态跟踪**
1. 在作业列表中实时查看运行状态和队列位置
2. 点击作业名查看详细执行信息、资源使用和运行日志
3. 监控GPU资源使用情况和预测进度

**步骤6: 结果获取与分析**
1. 作业完成后访问输出目录查看生成的结果文件
2. 获取PDB格式的三维结构文件和置信度数据
3. 查看工作目录中的ID映射表、性能统计和日志文件

**演示要点总结：**
- **用户友好**: 图形界面降低了使用门槛，适合各层次研究人员
- **自动化程度高**: 从序列处理、资源分配到结果整理全程自动化
- **实时监控**: 提供完整的作业状态跟踪和详细日志查看功能
- **结果丰富**: 输出包含结构文件、置信度评估、映射关系和性能数据

## 最佳实践

### 1. 项目组织建议

```bash title="推荐的项目目录结构"
parallelfold_project/
├── 01_input/                    # 输入数据
│   ├── raw_sequences/           # 原始FASTA文件
│   ├── cleaned_sequences/       # 清理后的序列
│   └── batch_groups/            # 按复杂度分组
│       ├── simple/
│       ├── medium/
│       └── complex/
├── 02_predictions/              # 预测结果
│   ├── monomer_results/         # 单体预测结果
│   ├── multimer_results/        # 复合物预测结果
│   └── batch_results/           # 批量处理结果
├── 03_analysis/                 # 结果分析
│   ├── quality_reports/         # 质量评估报告
│   ├── confidence_plots/        # 置信度图表
│   └── structural_analysis/     # 结构分析
├── scripts/                     # 运行脚本
│   ├── submit_jobs.sh           # 作业提交脚本
│   ├── monitor_progress.sh      # 进度监控脚本
│   └── analyze_results.py       # 结果分析脚本
└── logs/                       # 日志文件
    ├── submission_logs/         # 提交日志
    └── execution_logs/          # 执行日志
```

### 2. 质量控制流程

```python title="标准质量控制流程"
#!/usr/bin/env python3
"""ParallelFold质量控制流程"""

class ParallelFoldQC:
    def __init__(self, project_dir):
        self.project_dir = project_dir
        self.quality_thresholds = {
            'excellent': {'mean_plddt': 85, 'ptm': 0.8, 'high_conf_ratio': 0.6},
            'good': {'mean_plddt': 75, 'ptm': 0.6, 'high_conf_ratio': 0.4},
            'acceptable': {'mean_plddt': 65, 'ptm': 0.4, 'high_conf_ratio': 0.2}
        }
    
    def run_full_qc(self):
        """运行完整质量控制流程"""
        steps = [
            ("输入验证", self.validate_inputs),
            ("预测质量评估", self.assess_prediction_quality),
            ("结构合理性检查", self.check_structure_validity),
            ("生成质量报告", self.generate_quality_report),
            ("标记问题预测", self.flag_problematic_predictions)
        ]
        
        results = {}
        for step_name, step_func in steps:
            print(f"执行: {step_name}")
            try:
                result = step_func()
                results[step_name] = {"status": "success", "data": result}
            except Exception as e:
                results[step_name] = {"status": "failed", "error": str(e)}
        
        return results
    
    def validate_inputs(self):
        """验证输入文件质量"""
        # 实现输入验证逻辑
        pass
    
    def assess_prediction_quality(self):
        """评估预测质量"""
        # 实现质量评估逻辑
        pass
    
    def check_structure_validity(self):
        """检查结构合理性"""
        # 实现结构验证逻辑
        pass
```

### 3. 自动化流水线

```bash title="自动化处理流水线"
#!/bin/bash
# parallelfold_pipeline.sh - 完整自动化流水线

PIPELINE_DIR="$1"
CONFIG_FILE="$2"

if [[ ! -d "$PIPELINE_DIR" || ! -f "$CONFIG_FILE" ]]; then
    echo "用法: $0 <项目目录> <配置文件>"
    exit 1
fi

# 1. 环境准备
setup_environment() {
    echo "=== 环境准备 ==="
    mkdir -p "$PIPELINE_DIR"/{input,predictions,analysis,logs}
    
    # 加载配置
    source "$CONFIG_FILE"
    
    # 验证依赖
    command -v singularity >/dev/null || { echo "错误: 未找到singularity"; exit 1; }
    command -v sbatch >/dev/null || { echo "错误: 未找到SLURM"; exit 1; }
}

# 2. 输入处理
process_inputs() {
    echo "=== 输入处理 ==="
    
    # 清理和验证序列
    for fasta in "$PIPELINE_DIR/input"/*.fasta; do
        if [[ -f "$fasta" ]]; then
            echo "处理: $(basename $fasta)"
            python3 clean_fasta.py "$fasta" "${fasta%.fasta}_cleaned.fasta"
        fi
    done
    
    # 按复杂度分组
    group_sequences_by_complexity "$PIPELINE_DIR/input" "$PIPELINE_DIR/input/groups"
}

# 3. 批量提交
submit_predictions() {
    echo "=== 批量预测提交 ==="
    
    # 提交不同复杂度的预测任务
    submit_tiered_jobs "$PIPELINE_DIR/input/groups"
    
    # 记录作业ID
    squeue -u $USER -o "%.18i %.20j %.8u %.2t" > "$PIPELINE_DIR/logs/submitted_jobs.log"
}

# 4. 监控和收集结果
monitor_and_collect() {
    echo "=== 监控和结果收集 ==="
    
    # 等待所有作业完成
    while squeue -u $USER | grep -q "pf_"; do
        echo "等待作业完成... ($(date))"
        sleep 300  # 5分钟检查一次
    done
    
    # 收集结果
    find "$PIPELINE_DIR" -name "ranked_0.pdb" -exec cp {} "$PIPELINE_DIR/predictions/" \;
    find "$PIPELINE_DIR" -name "confidence.json" -exec cp {} "$PIPELINE_DIR/analysis/" \;
}

# 5. 质量分析
analyze_results() {
    echo "=== 结果质量分析 ==="
    
    # 运行质量评估
    python3 analyze_results.py "$PIPELINE_DIR/predictions" > "$PIPELINE_DIR/analysis/quality_report.txt"
    
    # 生成可视化
    python3 visualize_results.py "$PIPELINE_DIR/analysis" "$PIPELINE_DIR/analysis/plots"
    
    # 生成汇总报告
    generate_summary_report "$PIPELINE_DIR"
}

# 执行完整流水线
main() {
    echo "启动ParallelFold自动化流水线"
    echo "项目目录: $PIPELINE_DIR"
    echo "配置文件: $CONFIG_FILE"
    
    setup_environment
    process_inputs
    submit_predictions
    monitor_and_collect
    analyze_results
    
    echo "流水线执行完成!"
    echo "结果位置: $PIPELINE_DIR/predictions"
    echo "分析报告: $PIPELINE_DIR/analysis/quality_report.txt"
}

# 运行流水线
main
```

## 技术支持与资源

### 脚本模板库

所有脚本模板位于：`/hpcfs/fhome/demo/hpc/parallelfold/scripts/`
- `pf-monomer.slurm` - 单体蛋白预测模板
- `pf-multimer.slurm` - 复合物预测模板  
- `pf-batch.slurm` - 批量处理模板
- `pf-monitor.sh` - 作业监控工具

### 配置文件

配置示例位于：`/hpcfs/fhome/demo/hpc/parallelfold/configs/`
- `parallelfold_config.yaml` - 主配置文件

### 输入示例

示例文件位于：`/hpcfs/fhome/demo/hpc/parallelfold/examples/`
- `monomer_example.fasta` - 单体蛋白示例
- `multimer_example.fasta` - 复合物示例

### 在线资源

- **官方GitHub**: [https://github.com/Zuricho/ParallelFold](https://github.com/Zuricho/ParallelFold)
- **论文**: ParallelFold: Accelerating AlphaFold by Parallelizing Multiple Sequence Alignment
- **开发团队**: 上海交通大学 (Shanghai Jiao Tong University)
- **技术文档**: [GitHub Wiki](https://github.com/Zuricho/ParallelFold/wiki)

### 技术支持

如遇问题，请联系：
- **HPC技术支持**: support@hpc.cluster
- **ParallelFold专项支持**: parallelfold-support@hpc.cluster
- **CHESS平台支持**: chess-support@hpc.cluster

---

<head>
  <title>ParallelFold 高性能并行结构预测指南 | HPC文档</title>
  <meta
    name="description"
    content="详细介绍ParallelFold在HPC集群上进行高性能并行蛋白质结构预测的企业级完整指南，包括单体和复合物快速预测方法。"
  />
  <meta
    name="keywords"
    content="ParallelFold, AlphaFold, 并行计算, 蛋白质结构预测, 高性能计算, GPU加速, 结构基因组学"
  />
</head>